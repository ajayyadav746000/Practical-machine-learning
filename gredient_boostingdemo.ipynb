{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8c3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeece0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's load in our training data:\n",
    "\n",
    "train_data = pd.read_csv(\"titanic_train.csv\")\n",
    "#test_data = pd.read_csv(\"test.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c1e72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "train_data.drop(labels=\"Survived\", axis=1, inplace=True)\n",
    "full_data = train_data\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8fa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop any columns that aren't necessary or helpful for training, although you could leave them in and see how they affect things:\n",
    "\n",
    "drop_columns = [\"Name\", \"Age\", \"SibSp\", \"Ticket\", \"Cabin\", \"Parch\", \"Embarked\"]\n",
    "full_data.drop(labels=drop_columns, axis=1, inplace=True)\n",
    "#Any text data needs to be converted into numbers that our model can use, so let's change that now. We'll also fill any empty cells with 0:\n",
    "\n",
    "full_data = pd.get_dummies(full_data, columns=[\"Sex\"])\n",
    "full_data.fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a3cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_data.values[0:691]\n",
    "y_train=y_train.values[0:691]\n",
    "X_test = full_data.values[691:]\n",
    "#We'll now scale our data by creating an instance of the scaler and scaling it:\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#Now we can split the data into training and testing sets. Let's also set a seed (so you can replicate the results) and select the percentage of the data for testing on:\n",
    "\n",
    "state = 12  \n",
    "test_size = 0.30  \n",
    "  \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=test_size, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac51ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.787\n",
      "Accuracy score (validation): 0.755\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.822\n",
      "Accuracy score (validation): 0.736\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.824\n",
      "Accuracy score (validation): 0.731\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.839\n",
      "Accuracy score (validation): 0.750\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.859\n",
      "Accuracy score (validation): 0.745\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.851\n",
      "Accuracy score (validation): 0.745\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.870\n",
      "Accuracy score (validation): 0.731\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168958c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[97 18]\n",
      " [35 58]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.79       115\n",
      "           1       0.76      0.62      0.69        93\n",
      "\n",
      "    accuracy                           0.75       208\n",
      "   macro avg       0.75      0.73      0.74       208\n",
      "weighted avg       0.75      0.75      0.74       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we can evaluate the classifier by checking its accuracy and creating a confusion matrix. Let's create a new classifier and specify the best learning rate we discovered.\n",
    "\n",
    "gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "gb_clf2.fit(X_train, y_train)\n",
    "predictions = gb_clf2.predict(X_val)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df4b0c",
   "metadata": {},
   "source": [
    "#XGBoost Classifier\n",
    "Now we'll experiment with the XGBoost classifier.\n",
    "\n",
    "As before, let's start by importing the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "#Since our data is already prepared, we just need to fit the classifier with the training data:\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "Now that the classifier has been fit and trained, we can check the score it achieves on the validation set by using the score command.\n",
    "\n",
    "score = xgb_clf.score(X_val, y_val)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb6b11",
   "metadata": {},
   "source": [
    "Here's the output:\n",
    "\n",
    "0.7761194029850746\n",
    "Alternatively, you could predict the X_val data and then check the accuracy against the \n",
    "y_val by using accuracy_score. It should give you the same kind of result.\n",
    "\n",
    "Comparing the accuracy of XGboost to the accuracy of a regular gradient classifier shows that, in this case, the results were very similar. However, this won't always be the case and in different circumstances, one of the classifiers could easily perform better than the other. Try varying the arguments in this model to see how the result differ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
